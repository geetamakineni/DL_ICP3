{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_ICP3_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5ziio4bPwo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O02CYV6QbBa",
        "colab_type": "code",
        "outputId": "6733e518-acbc-4e30-d9f1-b54f031ad1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv',encoding='latin-1')\n",
        "print(df.head())\n",
        "df = df[df['label']!='unsup'] #Dropping Unnecessary labelfrom dataset\n",
        "sentences = df['review'].values\n",
        "y = df['label'].values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  type  ... label         file\n",
            "0           0  test  ...   neg      0_2.txt\n",
            "1           1  test  ...   neg  10000_4.txt\n",
            "2           2  test  ...   neg  10001_1.txt\n",
            "3           3  test  ...   neg  10002_3.txt\n",
            "4           4  test  ...   neg  10003_3.txt\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Hrpn9EQdz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kob4QHmiQwWB",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rqzAff_QgCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "max_review_len = max([len(s.split()) for s in sentences])\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
        "padded_train = pad_sequences(X_train_tokens,maxlen=max_review_len)\n",
        "paded_test = pad_sequences(X_test_tokens,maxlen=max_review_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB9nug5lQit-",
        "colab_type": "code",
        "outputId": "5cf2fa91-fc05-4b22-f274-7a2e4a4882a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=max_review_len))\n",
        "model.add(Flatten())\n",
        "model.add(layers.Dense(300, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid')) #changing number of neuron to 2 as we have only two labels Pos and Neg\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "history=model.fit(padded_train,y_train, epochs=5, verbose=True, validation_data=(paded_test,y_test), batch_size=256)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 37500 samples, validate on 12500 samples\n",
            "Epoch 1/5\n",
            "37500/37500 [==============================] - 251s 7ms/step - loss: 0.5407 - acc: 0.7463 - val_loss: 0.3070 - val_acc: 0.8703\n",
            "Epoch 2/5\n",
            "37500/37500 [==============================] - 252s 7ms/step - loss: 0.2480 - acc: 0.8998 - val_loss: 0.2991 - val_acc: 0.8742\n",
            "Epoch 3/5\n",
            "37500/37500 [==============================] - 259s 7ms/step - loss: 0.1819 - acc: 0.9324 - val_loss: 0.2956 - val_acc: 0.8797\n",
            "Epoch 4/5\n",
            "37500/37500 [==============================] - 291s 8ms/step - loss: 0.1082 - acc: 0.9680 - val_loss: 0.3381 - val_acc: 0.8710\n",
            "Epoch 5/5\n",
            "37500/37500 [==============================] - 256s 7ms/step - loss: 0.0511 - acc: 0.9908 - val_loss: 0.3757 - val_acc: 0.8710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK5rGukoQq_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "146a15dc-b0f7-4185-bb96-bf35a8665399"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(paded_test, y_test)\n",
        "print(test_acc)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500/12500 [==============================] - 29s 2ms/step\n",
            "0.870959997177124\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}